{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Watershed optimization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Imports and fns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "import os\n",
                "import time\n",
                "\n",
                "import geopandas as gpd\n",
                "import laspy as lp\n",
                "import matplotlib.pyplot as plt\n",
                "import napari\n",
                "import numpy as np\n",
                "import rasterio\n",
                "import scipy\n",
                "import scipy.ndimage as ndimage\n",
                "import scipy.ndimage.filters as filters\n",
                "import tifffile as tiff\n",
                "from scipy import interpolate\n",
                "from scipy.spatial import cKDTree as kdtree\n",
                "from skimage.color import label2rgb\n",
                "from skimage.measure import regionprops\n",
                "from skimage.segmentation import watershed\n",
                "from skimage.transform import resize\n",
                "import \n",
                "\n",
                "\n",
                "def las2chm(las_file):\n",
                "    las = lp.read(las_file)\n",
                "    points = las.xyz.copy()\n",
                "    return_num = las.return_number.copy()\n",
                "    num_of_returns = las.number_of_returns.copy()\n",
                "    classification = las.classification.copy()\n",
                "    select = classification != 5\n",
                "    select += (return_num == 1) * (num_of_returns == 1)\n",
                "    select += (return_num == 2) * (num_of_returns == 2)\n",
                "    select += (return_num == 3) * (num_of_returns == 3)\n",
                "    select += (return_num == 4) * (num_of_returns == 4)\n",
                "    select += (return_num == 5) * (num_of_returns == 5)\n",
                "    points = points[~select]\n",
                "    tr = kdtree(points)\n",
                "    distances, indices = tr.query(points, k=25, workers=-1)\n",
                "    distances = distances[:, -1]\n",
                "    thr = 2.0\n",
                "    select = distances > thr\n",
                "    points = points[~select]\n",
                "    orginal_points = las.xyz.copy()\n",
                "    tr = kdtree(orginal_points)\n",
                "    distances, indices = tr.query(points, k=10, workers=-1)\n",
                "    distances = distances[:, -1]\n",
                "    indices = np.unique(indices[distances < 0.5])\n",
                "    points = np.vstack((points, orginal_points[indices]))\n",
                "    slice_position = np.mean(points[:, 1])\n",
                "    width = 5\n",
                "    slice_org = np.sqrt((orginal_points[:, 1] - slice_position) ** 2) <= width\n",
                "    slice = np.sqrt((points[:, 1] - slice_position) ** 2) <= width\n",
                "    gridsize = 1.0  # [m]\n",
                "    ground_points = las.xyz[las.classification == 2]\n",
                "    grid_x = ((ground_points[:, 0] - ground_points[:, 0].min()) / gridsize).astype(\n",
                "        \"int\"\n",
                "    )\n",
                "    grid_y = ((ground_points[:, 1] - ground_points[:, 1].min()) / gridsize).astype(\n",
                "        \"int\"\n",
                "    )\n",
                "    grid_index = grid_x + grid_y * grid_x.max()\n",
                "    df = gpd.GeoDataFrame(\n",
                "        {\"gi\": grid_index, \"gx\": grid_x, \"gy\": grid_y, \"height\": ground_points[:, 2]}\n",
                "    )\n",
                "    df2 = df.sort_values([\"gx\", \"gy\", \"height\"], ascending=[True, True, True])\n",
                "    df3 = df2.groupby(\"gi\")[[\"gx\", \"gy\", \"height\"]].last()\n",
                "    grid_x = np.array(df3[\"gx\"])\n",
                "    grid_y = np.array(df3[\"gy\"])\n",
                "    max_height = np.array(df3[\"height\"])\n",
                "    DTM = np.ones((grid_x.max() + 1, grid_y.max() + 1)) * np.nan\n",
                "    DTM[grid_x, grid_y] = max_height\n",
                "    mask = np.isnan(DTM)\n",
                "    xx, yy = np.meshgrid(np.arange(DTM.shape[0]), np.arange(DTM.shape[1]))\n",
                "    valid_x = xx[~mask]\n",
                "    valid_y = yy[~mask]\n",
                "    newarr = DTM[~mask]\n",
                "    DTM_interp = interpolate.griddata(\n",
                "        (valid_x, valid_y), newarr.ravel(), (xx, yy), method=\"linear\"\n",
                "    )\n",
                "    gridsize = 1.0  # [m]\n",
                "    filt_points = points\n",
                "    grid_x = ((filt_points[:, 0] - filt_points[:, 0].min()) / gridsize).astype(\"int\")\n",
                "    grid_y = ((filt_points[:, 1] - filt_points[:, 1].min()) / gridsize).astype(\"int\")\n",
                "    grid_index = grid_x + grid_y * grid_x.max()\n",
                "    df = gpd.GeoDataFrame(\n",
                "        {\"gi\": grid_index, \"gx\": grid_x, \"gy\": grid_y, \"height\": filt_points[:, 2]}\n",
                "    )\n",
                "    df2 = df.sort_values([\"gx\", \"gy\", \"height\"], ascending=[True, True, True])\n",
                "    df3 = df2.groupby(\"gi\")[[\"gx\", \"gy\", \"height\"]].last()\n",
                "    grid_x = np.array(df3[\"gx\"])\n",
                "    grid_y = np.array(df3[\"gy\"])\n",
                "    max_height = np.array(df3[\"height\"])\n",
                "    DSM = np.ones((grid_x.max() + 1, grid_y.max() + 1)) * np.nan\n",
                "    DSM[grid_x, grid_y] = max_height\n",
                "    CHM = DSM - DTM_interp\n",
                "    CHM[np.isnan(CHM)] = 0\n",
                "    return CHM\n",
                "\n",
                "\n",
                "def ws_labels(CHM, ns=4, thr=3):\n",
                "    CHM_smooth = scipy.ndimage.gaussian_filter(CHM, thr)\n",
                "    CHM_max = ndimage.maximum_filter(CHM_smooth, ns)\n",
                "    local_maxima = CHM_smooth == CHM_max\n",
                "    local_maxima[CHM == 0] = 0\n",
                "    labeled, num_objects = ndimage.label(local_maxima)\n",
                "    xy = np.array(\n",
                "        ndimage.center_of_mass(\n",
                "            input=CHM, labels=labeled, index=range(1, num_objects + 1)\n",
                "        )\n",
                "    )\n",
                "\n",
                "\n",
                "\n",
                "# def ws_labels(CHM, ns=4, thr=3):\n",
                "#     CHM_smooth = scipy.ndimage.gaussian_filter(CHM, thr)\n",
                "#     CHM_max = ndimage.maximum_filter(CHM_smooth, ns)\n",
                "#     local_maxima = CHM_smooth == CHM_max\n",
                "#     local_maxima[CHM == 0] = 0\n",
                "#     labeled, num_objects = ndimage.label(local_maxima)\n",
                "#     xy = np.array(\n",
                "#         ndimage.center_of_mass(input=CHM, labels=labeled, index=range(1, num_objects + 1))\n",
                "#     )\n",
                "\n",
                "#     min_height = 2\n",
                "#     max_height = 40\n",
                "\n",
                "#     binary_mask = np.where(((CHM >= min_height) & (CHM <= max_height)), 1, 0)\n",
                "#     binary_mask = ndimage.binary_fill_holes(binary_mask).astype(int)\n",
                "\n",
                "#     labels = watershed(-CHM, labeled, mask=binary_mask)\n",
                "#     return labels\n",
                "\n",
                "\n",
                "    for region in regions:\n",
                "        if (\n",
                "            region.area >= area\n",
                "            and (region.axis_minor_length / region.axis_major_length >= ar)\n",
                "            and (region.eccentricity <= ecc)\n",
                "            and (region.area / region.area_bbox >= abr)\n",
                "            and (region.intensity_mean >= intensity)\n",
                "        ):\n",
                "            filtered_labels[region.coords[:, 0], region.coords[:, 1]] = region.label\n",
                "\n",
                "    return filtered_labels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Las -> CHM -> Loose & Strict Labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = \"../../../data/\"\n",
                "las_dir = f\"{data_dir}las/\"\n",
                "las_files = os.listdir(las_dir)\n",
                "out_dir = f\"{data_dir}watershed/\"\n",
                "\n",
                "# CHM params\n",
                "ns = 4\n",
                "thr = 3\n",
                "\n",
                "# Loose label params [area, ecc, ar, abr, intensity]\n",
                "loose_params = [40, 0.95, 0.1, 0.3, 80]\n",
                "# Strict label params\n",
                "strict_params = [55, 0.8, 0.5, 0.5, 115]\n",
                "keyword = \"strict\"\n",
                "\n",
                "for i, f in enumerate(las_files):\n",
                "    print(\"Reading files...\")\n",
                "    name = f.split(\".\")[0]\n",
                "    img_path = f\"{data_dir}watershed/RGBI_{name}.tif\"\n",
                "    img = tiff.imread(img_path)\n",
                "\n",
                "    print(\"Creating CHM...\")\n",
                "    chm = las2chm(las_dir + f)\n",
                "\n",
                "    print(\"Generating labels...\")\n",
                "    labels = ws_labels(chm)\n",
                "    labels = np.rot90(labels, 1)\n",
                "\n",
                "    print(\"Filtering regions...\")\n",
                "    labels = resize(labels, (img.shape[0], img.shape[1]), order=0)\n",
                "    filtered_labels = filter_labels(labels, img, 3, *strict_params)\n",
                "\n",
                "    print(\"Writing tif...\")\n",
                "    raster = rasterio.open(img_path)\n",
                "    new_dataset = rasterio.open(\n",
                "        f\"{out_dir}{name}_{keyword}_labels.tif\",\n",
                "        \"w\",\n",
                "        driver=\"GTiff\",\n",
                "        height=raster.height,\n",
                "        width=raster.width,\n",
                "        count=1,\n",
                "        dtype=np.dtype(int),\n",
                "        crs=raster.crs,\n",
                "        transform=raster.transform,\n",
                "    )\n",
                "\n",
                "    new_dataset.write(filtered_labels, 1)\n",
                "    new_dataset.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Explore the labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "viewer = napari.Viewer()\n",
                "img_dir = \"../../../data/watershed/\"\n",
                "label_dir = \"../../../data/watershed_imp/\"\n",
                "\n",
                "img = tiff.imread(img_dir + \"RGBI_Friedrichshain.tif\")\n",
                "labels = tiff.imread(label_dir + \"Friedrichshain_labels.tif\")\n",
                "\n",
                "viewer.add_image(img)\n",
                "viewer.add_labels(labels)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Grid search for optimal params"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# nsx = [3, 4, 5, 6]\n",
                "# thrx = [1.5, 2, 2.5, 3, 3.5]\n",
                "ns = 4\n",
                "thr = 3\n",
                "\n",
                "area = 40\n",
                "eccx = [0.8, 0.95]\n",
                "arx = [0.1, 0.5]\n",
                "abrx = [0.3, 0.5]\n",
                "intx = [80, 115]\n",
                "\n",
                "# Loose params\n",
                "ecc = 0.95\n",
                "ar = 0.1\n",
                "abr = 0.3\n",
                "intensity = 80\n",
                "\n",
                "# Strict params\n",
                "ecc = 0.8\n",
                "ar = 0.5\n",
                "abr = 0.5\n",
                "intensity = 115\n",
                "\n",
                "las_dir = \"../../../data/las/\"\n",
                "las_files = os.listdir(las_dir)\n",
                "\n",
                "chm = las2chm(las_dir + las_files[0])\n",
                "viewer = napari.Viewer()\n",
                "img = tiff.imread(\"../../../data/watershed/RGBI_Friedrichshain.tif\")\n",
                "viewer.add_image(img)\n",
                "for ecc in eccx:\n",
                "    for ar in arx:\n",
                "        for abr in abrx:\n",
                "            for intensity in intx:\n",
                "                labels = ws_labels(chm, ns, thr)\n",
                "                labels = resize(labels, (img.shape[0], img.shape[1]), order=0)\n",
                "                filtered_labels = filter_labels(labels, img, 3, *strict_params)\n",
                "                viewer.add_labels(\n",
                "                    filtered_labels,\n",
                "                    name=f\"ar={str(ar)}_ecc={str(ecc)}_abr={str(abr)}_int={str(intensity)}\",\n",
                "                    blending=\"opaque\",\n",
                "                )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Address bad automatic labels by \"masking\" bad labels with average intensity value in image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bad_labels = False\n",
                "if bad_labels:\n",
                "    data_dir = \"../../../data/watershed/\"\n",
                "    rgb_fn = glob.glob(f\"{data_dir}rgbi/*.tif\")\n",
                "    lab_l_fn = glob.glob(f\"{data_dir}labels/loose/*.tif\")\n",
                "    lab_s_fn = glob.glob(f\"{data_dir}labels/strict/*.tif\")\n",
                "    rgb_fn.sort()\n",
                "    lab_l_fn.sort()\n",
                "    lab_s_fn.sort()\n",
                "\n",
                "    for i in range(len(rgb_fn)):\n",
                "        # Load rgb and loose and strict labels\n",
                "        rgb = tiff.imread(rgb_fn[i])\n",
                "        lab_l = tiff.imread(lab_l_fn[i])\n",
                "        lab_s = tiff.imread(lab_s_fn[i])\n",
                "        # Get the mean values of each channel\n",
                "        rgb_mns = [rgb[..., j].mean() for j in range(rgb.shape[2])]\n",
                "        # Find where loose labels exist but not strict\n",
                "        idx = np.where((lab_l > 0) & (lab_s == 0))\n",
                "        # Replace values of \"bad\" labels with the channel mean\n",
                "        for k, m in enumerate(rgb_mns):\n",
                "            rgb[idx[0], idx[1], k] = m\n",
                "        # Save rgb\n",
                "        tiff.imwrite(rgb_fn[i].split(\"tif\")[0] + \"masked.tif\", rgb)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create \"ignore\" labels"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import glob\n",
                "import tifffile as tiff\n",
                "import numpy as np\n",
                "\n",
                "ignore = False\n",
                "if ignore:\n",
                "    data_dir = \"../../../data/watershed/\"\n",
                "    masked_dir = os.path.join(data_dir, \"labels/masked\")\n",
                "    lab_l_fn = glob.glob(f\"{data_dir}labels/loose/*.tif\")\n",
                "    lab_s_fn = glob.glob(f\"{data_dir}labels/strict/*.tif\")\n",
                "    lab_l_fn.sort()\n",
                "    lab_s_fn.sort()\n",
                "\n",
                "    if not os.path.exists(masked_dir):\n",
                "        os.makedirs(masked_dir)\n",
                "\n",
                "    for loose_fn, strict_fn in zip(lab_l_fn, lab_s_fn):\n",
                "        loose = tiff.imread(loose_fn)\n",
                "        strict = tiff.imread(strict_fn)\n",
                "        masked = strict.copy()\n",
                "        masked[np.where((loose > 0) & (strict == 0))] = -1\n",
                "        tiff.imwrite(\n",
                "            os.path.join(\n",
                "                masked_dir, f\"{loose_fn.split('/')[-1].split('_')[0]}_masked_labels.tif\"\n",
                "            ),\n",
                "            masked,\n",
                "        )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = \"../../../data/watershed/\"\n",
                "labels = glob.glob(f\"{data_dir}labels/masked/*.tif\")\n",
                "label = tiff.imread(labels[1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "viewer = napari.Viewer()\n",
                "viewer.add_labels(label)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Patchify Watershed Data (loose and strict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "do_it = False\n",
                "\n",
                "if do_it:\n",
                "    import os\n",
                "    import glob\n",
                "    import tifffile as tiff\n",
                "    from patchify import patchify\n",
                "\n",
                "    patch_size = 512\n",
                "    label_type = \"masked\"\n",
                "\n",
                "    data_dir = \"../../../data/watershed/\"\n",
                "    # Unpatchified directories\n",
                "    # unpatched_watershed_rgbi_dir = os.path.join(data_dir, f\"rgbi/{label_type}/\")\n",
                "    unpatched_watershed_label_dir = os.path.join(data_dir, f\"labels/{label_type}\")\n",
                "\n",
                "    # Patchified directories\n",
                "    # patched_watershed_rgbi_dest = os.path.join(data_dir, f\"rgbi/{label_type}/{patch_size}/\")\n",
                "    patched_watershed_label_dest = os.path.join(data_dir, f\"labels/{label_type}/{patch_size}/\")\n",
                "\n",
                "    # if not os.path.exists(patched_watershed_rgbi_dest):\n",
                "    #     os.makedirs(patched_watershed_rgbi_dest)\n",
                "\n",
                "    if not os.path.exists(patched_watershed_label_dest):\n",
                "        os.makedirs(patched_watershed_label_dest)\n",
                "\n",
                "    def patchify_watershed(rgbi_loc, lab_loc, rgbi_dest, lab_dest, patch_size):\n",
                "        # watershed_rgbi = glob.glob(os.path.join(unpatched_watershed_rgbi_dir, \"*.tif\"))\n",
                "        watershed_labels = glob.glob(\n",
                "            os.path.join(unpatched_watershed_label_dir, \"*.tif\")\n",
                "        )\n",
                "        # watershed_rgbi.sort()\n",
                "        watershed_labels.sort()\n",
                "\n",
                "        for k in range(len(watershed_rgbi)):\n",
                "            # rgbi_name = watershed_rgbi[k].split(\"/\")[-1].split(\".tif\")[0]\n",
                "            label_name = watershed_labels[k].split(\"/\")[-1].split(\".tif\")[0]\n",
                "\n",
                "            # patches_train = patchify(\n",
                "            #     tiff.imread(watershed_rgbi[k]),\n",
                "            #     (patch_size, patch_size, 4),\n",
                "            #     step=patch_size,\n",
                "            # )\n",
                "\n",
                "            patches_label = patchify(\n",
                "                tiff.imread(watershed_labels[k]),\n",
                "                (patch_size, patch_size),\n",
                "                step=patch_size,\n",
                "            )\n",
                "\n",
                "            for i in range(patches_train.shape[0]):\n",
                "                for j in range(patches_train.shape[1]):\n",
                "                    tiff.imwrite(\n",
                "                        f\"{patched_watershed_rgbi_dest}{rgbi_name}_{i}_{j}.tif\",\n",
                "                        patches_train[i, j, 0, :, :, :],\n",
                "                    )\n",
                "                    tiff.imwrite(\n",
                "                        f\"{patched_watershed_label_dest}{label_name}_{i}_{j}.tif\",\n",
                "                        patches_label[i, j, :, :],\n",
                "                    )\n",
                "\n",
                "    patchify_watershed(\n",
                "        unpatched_watershed_rgbi_dir,\n",
                "        unpatched_watershed_label_dir,\n",
                "        patched_watershed_rgbi_dest,\n",
                "        patched_watershed_label_dest,\n",
                "        patch_size,\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Explore labels and region props in plotly"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# img = tiff.imread(\"../../../data/watershed/RGBI_Friedrichshain.tif\")\n",
                "# labels = ws_labels(chm, 4, 3)\n",
                "# labels = resize(labels, (img.shape[0], img.shape[1]), order=0)\n",
                "# labels = np.rot90(labels, 1)\n",
                "# regions = regionprops(labels, img)\n",
                "\n",
                "# import plotly\n",
                "# import plotly.express as px\n",
                "# import plotly.graph_objects as go\n",
                "# from skimage import data, filters, measure, morphology\n",
                "\n",
                "# dim = 1000\n",
                "# img = img[0:dim, 0:dim, 1]\n",
                "# labels = labels[0:dim, 0:dim]\n",
                "\n",
                "# fig = px.imshow(img, binary_string=True, width=dim, height=dim)\n",
                "# fig.update_traces(hoverinfo=\"skip\")  # hover is only for label info\n",
                "\n",
                "\n",
                "# props = measure.regionprops(labels, img)\n",
                "# properties = [\"area\", \"eccentricity\", \"perimeter\", \"intensity_mean\"]\n",
                "\n",
                "# # For each label, add a filled scatter trace for its contour,\n",
                "# # and display the properties of the label in the hover of this trace.\n",
                "# for index in range(0, len(np.unique(labels)) - 1):\n",
                "#     label_i = props[index].label\n",
                "#     contour = measure.find_contours(labels == label_i, 0.5)[0]\n",
                "#     y, x = contour.T\n",
                "#     hoverinfo = \"\"\n",
                "#     for prop_name in properties:\n",
                "#         hoverinfo += f\"<b>{prop_name}: {np.mean(getattr(props[index], prop_name)):.2f}</b><br>\"\n",
                "#     fig.add_trace(\n",
                "#         go.Scatter(\n",
                "#             x=x,\n",
                "#             y=y,\n",
                "#             name=label_i,\n",
                "#             mode=\"lines\",\n",
                "#             fill=\"toself\",\n",
                "#             showlegend=False,\n",
                "#             hovertemplate=hoverinfo,\n",
                "#             hoveron=\"points+fills\",\n",
                "#         )\n",
                "#     )\n",
                "\n",
                "# plotly.io.show(fig)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "vscode": {
            "interpreter": {
                "hash": "bf136276df7b73f579d00ffc03546cf27d68eba258d4f2ea564dd7fb6a9dd1fb"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}