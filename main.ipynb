{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278a6d15-2b2b-4998-a19b-ac114ed0ce99",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparing instance segmentation of trees and watershed-based instance segmentation of semantically segmented trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c3865-3d4a-4ccb-8c91-d74a393641c9",
   "metadata": {},
   "source": [
    "## To-dos\n",
    "- **Perform grid search to determine best hyperparameters (batch size, epochs, learning rate)**\n",
    "    - Don't forget to also incorporate KFolds CV!\n",
    "- **Improve quality of watershed labels**\n",
    "    - Review the labels and remove non-tree labels\n",
    "- **Generate boundaries on label data**\n",
    "    - Only applicable if using the U-Net approach (I think?)\n",
    "    - Consider using a positive boundary (dilate) and a negative (erode) and compare\n",
    "- **Incorporate KFolds (10 folds) cross-validation into model training**\n",
    "    - I.e. Leave a test set alone and then use KFolds on the training set to derive train/val subsets)\n",
    "- **Consider the Mask RCNN approach: https://github.com/matterport/Mask_RCNN**\n",
    "   \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ee39e-760c-4c0f-909e-f5724138ea3d",
   "metadata": {},
   "source": [
    "## Instance segmentation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6763067-39be-4621-a43a-6890cdb45898",
   "metadata": {},
   "source": [
    "### Imports and function defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7823f-368b-494e-b6f0-26a0a49d2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from patchify import patchify\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "\n",
    "def patch_train_label(raster, labels, img_size, channels=False, merge_channel=False):\n",
    "    samp_rast = tiff.imread(raster[0])\n",
    "    img_base_size = samp_rast.shape[0]\n",
    "    n = len(raster)\n",
    "    m = (img_base_size // img_size) ** 2\n",
    "\n",
    "    if not channels:\n",
    "        channels = samp_rast.shape[-1]\n",
    "\n",
    "    if merge_channel:\n",
    "        channels += tiff.imread(merge_channel[0]).shape[-1]\n",
    "\n",
    "    data_train = np.zeros((n * m, img_size, img_size, channels))\n",
    "    data_label = np.zeros((n * m, img_size, img_size))\n",
    "\n",
    "    for k in range(n):\n",
    "        if merge_channel:\n",
    "            r = np.concatenate(\n",
    "                (tiff.imread(raster[k]), tiff.imread(merge_channel[k])), axis=-1\n",
    "            )\n",
    "        else:\n",
    "            r = tiff.imread(raster[k])[..., :channels]\n",
    "\n",
    "        # Only read in the specified number of channels from input raster\n",
    "        patches_train = patchify(\n",
    "            r,\n",
    "            (img_size, img_size, channels),\n",
    "            step=img_size,\n",
    "        )\n",
    "        patches_label = patchify(\n",
    "            tiff.imread(labels[k]), (img_size, img_size), step=img_size\n",
    "        )\n",
    "        data_train[k * m : (k + 1) * m, :, :, :] = patches_train.reshape(\n",
    "            -1, img_size, img_size, channels\n",
    "        )\n",
    "        data_label[k * m : (k + 1) * m, :, :] = patches_label.reshape(\n",
    "            -1, img_size, img_size\n",
    "        )\n",
    "\n",
    "    data_label = (data_label > 0).astype(\"int\")\n",
    "    data_label = np.expand_dims(data_label, axis=-1)\n",
    "    data_train = data_train.astype(\"float\") / 255\n",
    "\n",
    "    print(\n",
    "        f\"\\nData sizes:\\ndata_train: {data_train.shape}\\ndata_label: {data_label.shape}\\n\"\n",
    "    )\n",
    "\n",
    "    return data_train, data_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6696e7d-8633-44e0-802d-f6be59bd0da6",
   "metadata": {},
   "source": [
    "### Load, patchify, and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2a2ea-2863-4e62-ad3f-23daa79494b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patchify hand-labeled data PLUS NIR data\n",
    "data_dir = \"../data/\"\n",
    "hand_rgb_dir = f\"{data_dir}train_rgb/\"\n",
    "hand_nir_dir = f\"{data_dir}train_nir/\"\n",
    "hand_label_dir = f\"{data_dir}label/\"\n",
    "\n",
    "patch_rgb = glob.glob(f\"{hand_rgb_dir}*.tif\")\n",
    "patch_nir = glob.glob(f\"{hand_nir_dir}*.tif\")\n",
    "patch_label = glob.glob(f\"{hand_label_dir}*.tif\")\n",
    "patch_rgb.sort()\n",
    "patch_label.sort()\n",
    "\n",
    "print(\"Patchifying RGB + NIR data...\")\n",
    "data_train, data_label = patch_train_label(\n",
    "    patch_rgb, patch_label, 128, merge_channel=patch_nir\n",
    ")\n",
    "\n",
    "# Patchify watershed data (pre-patchified)\n",
    "patched_watershed_rgbi_dir = f\"{data_dir}watershed/512/rgbi/\"\n",
    "patched_watershed_label_dir = f\"{data_dir}watershed/512/labels/\"\n",
    "\n",
    "watershed_rgbi = glob.glob(f\"{patched_watershed_rgbi_dir}*.tif\")\n",
    "watershed_labels = glob.glob(f\"{patched_watershed_label_dir}*.tif\")\n",
    "watershed_rgbi.sort()\n",
    "watershed_labels.sort()\n",
    "\n",
    "print(\"Patchifying watershed data...\")\n",
    "data_train_ws, data_label_ws = patch_train_label(watershed_rgbi, watershed_labels, 128)\n",
    "\n",
    "data_train = np.vstack((data_train, data_train_ws))\n",
    "data_label = np.vstack((data_label, data_label_ws))\n",
    "\n",
    "print(\n",
    "    f\"\\nSizes after adding watershed data:\\n\\\n",
    "data_train: {data_train.shape}\\n\\\n",
    "data_label: {data_label.shape}\\n\"\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data_train, data_label, test_size=0.1, random_state=157\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nSizes after splitting data:\\n\\\n",
    "x_train: {x_train.shape}\\n\\\n",
    "y_train: {y_train.shape}\\n\\\n",
    "x_test: {x_test.shape}\\n\\\n",
    "y_test: {y_test.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda8a901-da6d-4a7b-8468-eb7a044120e5",
   "metadata": {},
   "source": [
    "## Messing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b54f4-0996-4a7f-abfe-dfd7a9e697bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_fn = glob.glob(\"../data/watershed/512/labels/*.tif\")\n",
    "im = tiff.imread(im_fn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d9062a-63ca-45b3-88bd-e92a9a7ea014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb5f57-be0b-40f6-a5be-558855f48412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im.astype(\"float\")\n",
    "im[im == 0] = np.nan\n",
    "plt.imshow(im, cmap=plt.cm.tab20c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64c30c-634a-421f-af0c-bfd881129db1",
   "metadata": {},
   "source": [
    "## Semantic watershed segmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lusk_dap05",
   "language": "python",
   "name": "lusk_dap05"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
